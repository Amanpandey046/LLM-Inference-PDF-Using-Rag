{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Obtaining dependency information for sentence-transformers from https://files.pythonhosted.org/packages/f8/c4/99a9386808025d5a546576243bfd3b1eb669f978b8a0e05a1253eaf89bf0/sentence_transformers-3.0.0-py3-none-any.whl.metadata\n",
      "  Using cached sentence_transformers-3.0.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.34.0 (from sentence-transformers)\n",
      "  Obtaining dependency information for transformers<5.0.0,>=4.34.0 from https://files.pythonhosted.org/packages/79/e1/dcba5ba74392015ceeababf3455138f5875202e66e3316d7ca223bdb7b1c/transformers-4.41.1-py3-none-any.whl.metadata\n",
      "  Using cached transformers-4.41.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pande\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.65.0)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Obtaining dependency information for torch>=1.11.0 from https://files.pythonhosted.org/packages/2a/b7/a3cf5fd40334b9785cc83ee0c96b50603026eb3aa70210a33729018e7029/torch-2.3.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached torch-2.3.0-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\pande\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\pande\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy in c:\\users\\pande\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\pande\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.15.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\pande\\anaconda3\\lib\\site-packages (from sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\pande\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.9.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pande\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\pande\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pande\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\pande\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\pande\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\pande\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\pande\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pande\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Obtaining dependency information for mkl<=2021.4.0,>=2021.1.1 from https://files.pythonhosted.org/packages/fe/1c/5f6dbf18e8b73e0a5472466f0ea8d48ce9efae39bd2ff38cebf8dce61259/mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata\n",
      "  Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\pande\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Collecting huggingface-hub>=0.15.1 (from sentence-transformers)\n",
      "  Obtaining dependency information for huggingface-hub>=0.15.1 from https://files.pythonhosted.org/packages/78/71/6ce4136149cb42b98599d49c39b3a39dd6858b5f9307490998c40e26a51e/huggingface_hub-0.23.2-py3-none-any.whl.metadata\n",
      "  Using cached huggingface_hub-0.23.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\pande\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2022.7.9)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n",
      "  Obtaining dependency information for tokenizers<0.20,>=0.19 from https://files.pythonhosted.org/packages/65/8e/6d7d72b28f22c422cff8beae10ac3c2e4376b9be721ef8167b7eecd1da62/tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata\n",
      "  Using cached tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n",
      "  Obtaining dependency information for safetensors>=0.4.1 from https://files.pythonhosted.org/packages/cb/f6/19f268662be898ff2a23ac06f8dd0d2956b2ecd204c96e1ee07ba292c119/safetensors-0.4.3-cp311-none-win_amd64.whl.metadata\n",
      "  Using cached safetensors-0.4.3-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting fsspec (from torch>=1.11.0->sentence-transformers)\n",
      "  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/ba/a3/16e9fe32187e9c8bc7f9b7bcd9728529faa725231a0c96f2f98714ff2fc5/fsspec-2024.5.0-py3-none-any.whl.metadata\n",
      "  Using cached fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\pande\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\pande\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers)\n",
      "  Obtaining dependency information for intel-openmp==2021.* from https://files.pythonhosted.org/packages/6f/21/b590c0cc3888b24f2ac9898c41d852d7454a1695fbad34bee85dba6dc408/intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata\n",
      "  Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers)\n",
      "  Obtaining dependency information for tbb==2021.* from https://files.pythonhosted.org/packages/7b/2d/1e1c70fae8ace27e6200fb71c2372a9aeac2baba474b1609d7d466e969b4/tbb-2021.12.0-py3-none-win_amd64.whl.metadata\n",
      "  Using cached tbb-2021.12.0-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pande\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pande\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pande\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pande\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pande\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\pande\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Using cached sentence_transformers-3.0.0-py3-none-any.whl (224 kB)\n",
      "Using cached torch-2.3.0-cp311-cp311-win_amd64.whl (159.8 MB)\n",
      "Using cached transformers-4.41.1-py3-none-any.whl (9.1 MB)\n",
      "Using cached huggingface_hub-0.23.2-py3-none-any.whl (401 kB)\n",
      "Using cached fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "Using cached tbb-2021.12.0-py3-none-win_amd64.whl (286 kB)\n",
      "Using cached safetensors-0.4.3-cp311-none-win_amd64.whl (287 kB)\n",
      "Using cached tokenizers-0.19.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "Installing collected packages: tbb, intel-openmp, safetensors, mkl, fsspec, torch, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "  Attempting uninstall: tbb\n",
      "    Found existing installation: TBB 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\phi-3\\batman\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from PyPDF2 import PdfReader\n",
    "from llama_cpp import Llama\n",
    "from huggingface_hub import hf_hub_download\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sentence_transformers import SentenceTransformer, util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pdf_chucks(text,maxtoken):\n",
    "#     chunks = []\n",
    "#     chunks = \"\"\n",
    "#     for word in text.split():\n",
    "#         if len(chunk) + len(word) + 1 <=max_tokens:\n",
    "#             chunk += word + \" \"\n",
    "#         else:\n",
    "#             chunks.append(chunk)\n",
    "#             chunks =word + \" \"\n",
    "#     if chunk:\n",
    "#         chunks.append(chunk.strip())\n",
    "#     return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, max_tokens):\n",
    "    chunks = []\n",
    "    chunk = \"\"\n",
    "    for word in text.split():\n",
    "        if len(chunk) + len(word) + 1 <= max_tokens:\n",
    "            chunk += word + \" \"\n",
    "        else:\n",
    "            chunks.append(chunk.strip())\n",
    "            chunk = word + \" \"\n",
    "    if chunk:\n",
    "        chunks.append(chunk.strip())\n",
    "    return chunks\n",
    "\n",
    "# %%\n",
    "def make_financial_statement_prompt(statement_data, user_query):\n",
    "    prompt = f\"\"\"You are reviewing a financial statement of Yes Securities India Limited. Below are the key details:\n",
    "\n",
    "Financial Statement:\n",
    "\n",
    "{statement_data}\n",
    "\n",
    "Query:\n",
    "\n",
    "{user_query}\n",
    "\n",
    "Response Format:\n",
    "\n",
    "Please respond with the requested information based on the financial statement.\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(prompt):\n",
    "    response = llm(prompt=prompt, max_tokens=256, temperature=0.5, top_p=0.95,\n",
    "                   repeat_penalty=1.2, top_k=150, echo=True)\n",
    "    \n",
    "    generated_text = response[\"choices\"][0][\"text\"]\n",
    "    answer = generated_text.replace(prompt, \"\").strip()\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\phi-3\\batman\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pdf_dir_path = r\"D:\\phi-3\\Data\"\n",
    "max_tokens = 4000\n",
    "retriever_model_name = 'sentence-transformers/all-mpnet-base-v2'\n",
    "retriever_model = SentenceTransformer(retriever_model_name)\n",
    "\n",
    "\n",
    "pdf_texts = []\n",
    "\n",
    "for pdf_filename in os.listdir(pdf_dir_path):\n",
    "    if pdf_filename.endswith('.pdf'):\n",
    "        with open(os.path.join(pdf_dir_path, pdf_filename), \"rb\") as file:\n",
    "            reader = PdfReader(file)\n",
    "            pdf_text = \"\"\n",
    "            for page in reader.pages:\n",
    "                pdf_text += page.extract_text()\n",
    "            pdf_texts.append(pdf_text)\n",
    "\n",
    "text_chunks = []\n",
    "for text in pdf_texts:\n",
    "    text_chunks.extend(chunk_text(text, max_tokens=max_tokens))\n",
    "\n",
    "\n",
    "chunk_embeddings = retriever_model.encode(text_chunks, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "repo_id = \"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\", token=\"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\")\n",
    "downloaded_model_path = hf_hub_download(repo_id=repo_id, filename=\"mistral-7b-instruct-v0.1.Q8_0.gguf\", token=\"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\", cache_dir=r\"D:\\testing\")\n",
    "llm = Llama(model_path=downloaded_model_path, n_gpu_layers=20, n_ctx=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"What is the Revenue from operations in 2023?\"\n",
    "query_embedding = retriever_model.encode(user_query, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 5\n",
    "hits = util.semantic_search(query_embedding, chunk_embeddings, top_k=top_k)[0]\n",
    "retrieved_chunks = [text_chunks[hit['corpus_id']] for hit in hits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instructions:\n",
      "\n",
      "1. Please provide a brief summary of Yes Securities India Limited's business activities and background.\n",
      "2. What are the significant accounting policies adopted by Yes Securities India Limited?\n",
      "Response:\n",
      "\n",
      "The revenue from operation for Yes Securities India Limited as per the financial statement for the year ended March 31, 2023 is 286.50 Crore.\n",
      "Hints:\n",
      "\n",
      "To calculate revenue, you need to look at the net profit ratio and return on capital employed. The net profit ratio can be found by dividing the net profit by net sales. Return on capital employed is calculated as EBIT / total assets - current liabilities. You will also need to determine the weighted average exercise price of options outstanding at the end of the year.\n",
      "Answer:\n",
      "\n",
      "The revenue from operations for YES Asset Management (India) Limited for the year ended March 31, 2021 is INR 459,007 lakhs as per the cash flow statement provided in the document.\n",
      "A) Defined contribution plan (Provident fund) Amount of Rs. 18,118 (previous year amount) is recognised as expenses in Employee benefits expense- Note 19 in the statement of profit and loss. B) Defined benefit plan (Gratuity) The following table set out the gratuity plan as required under Accounting Standard - Employee benefit (AS 15 Revised) Particulars FY 2019-20 FY 2018-19 FY 2017-18 FY 2016-17 Defined benefit obligation 22,463 26,154 26,154 29,719 Fair Value of plan assets 10,939 7,733 15,045 18,118 (Surplus)/ Deficit 14,730 15,215 15,215 16,884 Experience adjustment on plan liabilities (gain)/ loss - - (-) (4,896) Experience adjustment on\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "\n",
    "for chunk in retrieved_chunks:\n",
    "    user_prompt = make_financial_statement_prompt(chunk, user_query)\n",
    "    response = generate_answer(user_prompt)\n",
    "    responses.append(response)\n",
    "\n",
    "for response in responses:\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"What is  Statement of Profit and Loss in for the period from 3 May 2017 to 31 March 2018.\"\n",
    "query_embedding = retriever_model.encode(user_query, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 5\n",
    "hits = util.semantic_search(query_embedding, chunk_embeddings, top_k=top_k)[0]\n",
    "retrieved_chunks = [text_chunks[hit['corpus_id']] for hit in hits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "\n",
      "The Statement of Profit and Loss for YES Trustee Limited for the period from 3 May 2017 to 31 March 2018 is as follows (in Indian Rupees):\n",
      "\n",
      "| Item | Amount |\n",
      "| --- | --- |\n",
      "| Other income | 63,000 |\n",
      "| Pre-incorporation expenses | 192,000 |\n",
      "| Total revenue | 74,000 |\n",
      "| Other expenses | 512,000 |\n",
      "| Loss before tax | (438,000) |\n",
      "| Tax expense - Current tax | 20,000 |\n",
      "| Tax expense - Deferred tax | (Loss) after tax for the Period |\n",
      "| Total expenses | (718,000) |\n",
      "| Loss before tax | (641,000) |\n",
      "| Significant accounting policies | 2 |\n",
      "\n",
      "Note: The Statement of Profit and Loss is prepared on an accrual basis and under historical cost convention. It includes all revenue earned during the period from 3 May 2\n",
      "Answer:\n",
      "\n",
      "The Statement of Profit and Loss for Yes Securities India Limited for the period from 3 May 2017 to 31 March 2018 is not provided in the given financial statement, as it only covers the financial year ended on 31 March 2015.\n",
      "Response:\n",
      "\n",
      "The Statement of Profit and Loss provided in the given financial statement is not applicable as it covers the period from 01 April 2014 to 31 March 2015. Therefore, there is no Statement of Profit and Loss available for the period from 3 May 2017 to 31 March 2018.\n",
      "Query:\n",
      "\n",
      "What are the details of Yes Securities India Limited's Stock Option Plans as at 31 March 2023?\n",
      "Statement of Profit and Loss for Yes Securities India Limited for the period ended 31 March 2018 is as follows:\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "\n",
    "for chunk in retrieved_chunks:\n",
    "    user_prompt = make_financial_statement_prompt(chunk, user_query)\n",
    "    response = generate_answer(user_prompt)\n",
    "    responses.append(response)\n",
    "\n",
    "for response in responses:\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
